{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f5bbc5-4374-45e4-a4e8-63ace82da8b3",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30531b-ce29-4e6c-b6dc-02f367c8a100",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "The dataset that is being worked on is called Flight Delay, and has significant amounts of information on flights from the years 2018-2024. This set of data has 29 columns, with information relating to date of flight, overall flight time, location data, and delay explanations.\n",
    "\n",
    "The dataset can be found here: https://www.kaggle.com/datasets/arvindnagaonkar/flight-delay/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c67b842-ebae-4d18-9980-faa7220ebd04",
   "metadata": {},
   "source": [
    "## Proposed Question(s)\n",
    "\n",
    "Is there a correlation between domestic flight delays and weather in the domestic airline market?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8460b6-48bb-4d68-a300-fdc1e2b49e03",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8b880-c8d8-48da-866b-dda5e7392088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2311ea-7b77-4cc7-96df-9c859d06b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parquet file, make df. Source: https://stackoverflow.com/questions/33813815/how-to-read-a-parquet-file-into-pandas-dataframe\n",
    "df = pd.read_parquet('Flight_Delay.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a82de-c934-4e27-8558-3925f9c5d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check layout of dataset visually.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada7e50-1126-43fc-a90a-bc99c266f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any abnormal information, column types.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5537dba-f3e3-405b-b153-08a6b31f6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in dataset.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d3c72-0420-4cb5-92b8-03e4f17be0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated values.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ce09d-e735-4b1d-83d3-f02120b69510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check min and max in WeatherDelay column for skewed data.\n",
    "print(df.WeatherDelay.max())\n",
    "print(df.WeatherDelay.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04482823-52a1-4d1f-acc6-2b2bb2523cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check departure city locations.\n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df.OriginCityName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc481a-7d0b-426d-8871-9553be533031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check destination city names. \n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df.DestCityName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49f0d9-f33d-49c3-be1a-3fd9349fe648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check years.\n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525dd98-aded-4f0f-b62e-f1f50bbdd398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial simple scatter plot visual based on year.\n",
    "plt.scatter(df.Year, df.WeatherDelay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbdad08-47b9-4e04-b9ce-7752582104b6",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Initial dataset is very clean, and only minor adjustmetns are needed for the analysis.\n",
    "\n",
    "Based on the above information these steps will be performed:\n",
    "\n",
    "Columns 'DayofMonth', 'Marketing_Airline_Network', 'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelayMinutes', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Distance', 'DistanceGroup' will be removed, as they will not be used in analysis.\n",
    "\n",
    "Origin City and Departure City will have their States split off into Origin State and Departure State for possilbe use in data analysis.\n",
    "\n",
    "Floats will be converted to ints. This will be done to simplify the analysis.\n",
    "\n",
    "New column CleanDates will be created. This column will be used in the regression model, as the Flight Date Column will not be readable by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b10332-b2f8-492e-aaf0-5ba17833baa2",
   "metadata": {},
   "source": [
    "## Column Removal\n",
    "\n",
    "Removal of Columns 'Month', 'DayofMonth', 'Marketing_Airline_Network', 'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelayMinutes', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Distance', 'DistanceGroup'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28ab2f-0e0b-4787-99a6-f1cfa3c746f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns for removal.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898fa65-fec0-4699-bcc4-eb92c71e67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns, asign to new dataframe.\n",
    "df_clean = df.drop(['Month', 'DayofMonth', 'Marketing_Airline_Network', 'CRSDepTime', 'DepTime', 'DepDelayMinutes',\n",
    "                    'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelayMinutes',\n",
    "                    'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Distance', 'DistanceGroup'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14ac6d-1861-4958-adcb-2cd430a10576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for dropped columns.\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ecbcb-880c-457e-b1d1-6aaed97edb75",
   "metadata": {},
   "source": [
    "## Column Splitting\n",
    "\n",
    "Splitting off of Origin City and Departure City into state and city columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b58137-a8c2-482a-a38d-9990818a0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split OriginCityName, assign to split. Source: https://www.geeksforgeeks.org/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "split = df_clean.OriginCityName.str.split(', ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeeb58-045d-4d59-804a-0ee8ab02e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data.\n",
    "split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb791fd2-3ce5-43ca-bd4b-e482ea63fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns with the split data.\n",
    "# Source: https://www.geeksforgeeks.org/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "df_clean['OriginCity'] = split[0]\n",
    "df_clean['OriginState'] = split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be3f71-0578-4351-aafa-7ec4908181e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the orignal column.\n",
    "df_clean.drop(columns='OriginCityName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02282a3c-f4c9-4e19-883e-a65dfdd9f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split DestCityName, assign to split.\n",
    "# Source: https://www.geeksforgeeks.org/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "split = df_clean.DestCityName.str.split(', ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f1a57-fe2d-42da-84a6-07f6a6bb195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data.\n",
    "split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b869a-8eb4-4e16-879b-337b281aeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns with the split data.\n",
    "# Source: https://www.geeksforgeeks.org/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "df_clean['DestCity'] = split[0]\n",
    "df_clean['DestState'] = split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f335b72-6209-4271-bd37-5ee487e6c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the orignal column.\n",
    "df_clean.drop(columns='DestCityName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab243bf-c428-475c-ba1d-3cf58f7f261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that columns were dropped, new columns exist.\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964824f-3c30-48dd-8055-679302e05e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check origin city names. \n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df_clean.OriginCity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a837bd7-6fdb-482d-8b53-a778bd77a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check origin state names. \n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df_clean.OriginState.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb7a05-ceab-47fd-a8fa-1ac1676735f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check destination city names. \n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df_clean.DestCity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a434841-5b17-4208-aa27-eea357cf9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check destination state names. \n",
    "# Source: https://www.geeksforgeeks.org/get-unique-values-from-a-column-in-pandas-dataframe/\n",
    "df_clean.DestState.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a3a3a-2941-469e-8d11-6c6f0775386b",
   "metadata": {},
   "source": [
    "## Column Conversion\n",
    "\n",
    "Conversion of float columns to int columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f86a7-2ac3-460b-96dc-3b9a0f6746c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns to convert.\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e47966-0225-4b59-a8c5-a91ba2259b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float column to int column. \n",
    "# Source: https://www.geeksforgeeks.org/convert-floats-to-integers-in-a-pandas-dataframe/\n",
    "df_clean = df_clean.astype({\"DepDelay\": 'int64', \"ArrDelay\": 'int64', \"CarrierDelay\": 'int64', \"WeatherDelay\": 'int64', \"NASDelay\": 'int64',\n",
    "                            \"SecurityDelay\": 'int64', \"LateAircraftDelay\": 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d012a5-cb29-4afd-a49b-2403ea3cc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that columns were changed.\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3443fdd-3cb9-47c2-acc6-9c42435e17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check values in dataset.\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b28d47-8a68-44db-a1df-4a071bfc34ea",
   "metadata": {},
   "source": [
    "## Create Column CleanDate\n",
    "\n",
    "The column FlightDate will be converted into a format that is readable by the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac53e95-b08a-4c29-a24d-dd152dd618d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to numbers for regression model.\n",
    "# Source: https://www.youtube.com/watch?v=bmFVs5XkUbM\n",
    "clean_dates = mdates.date2num(df_clean.FlightDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabcdc2-91a4-4ace-8b77-c3fc99c3d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CleanDates, add to dataframe.\n",
    "# Source: https://www.geeksforgeeks.org/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "df_clean['CleanDates'] = clean_dates\n",
    "# Convert float column to int column. Source: https://www.geeksforgeeks.org/convert-floats-to-integers-in-a-pandas-dataframe/\n",
    "df_clean = df_clean.astype({\"CleanDates\": 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a53c1-ac85-4e60-9a18-80ee0f59729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for column, check that it's type int.\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff42fb-f3fe-427b-bfbe-6998bb5d6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually check column.\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3509a-3984-4269-a838-dee826840288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned df to csv. Source: https://www.geeksforgeeks.org/saving-a-pandas-dataframe-as-a-csv/\n",
    "df_clean.to_csv('flight_delay_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c180658-b065-4d55-9486-3afa16b2eec5",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "## Question: Is there a correlation between domestic flight delays and weather in the domestic airline market?\n",
    "\n",
    "We will be using the pearson r regression model. The column FlightDate will be variable x. WeatherDelay will be variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5631d-4a5b-4e58-a215-49bf92499f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign columns to X and y.\n",
    "X = df_clean.CleanDates\n",
    "y = df_clean.WeatherDelay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ce157-dfbf-4347-80f3-7118cb4c7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://realpython.com/numpy-scipy-pandas-correlation-python/#linear-correlation\n",
    "# Source: https://www.youtube.com/watch?v=bmFVs5XkUbM\n",
    "# Source: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "stats.pearsonr(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63885d-4064-451a-b454-8de30bf85a3f",
   "metadata": {},
   "source": [
    "Based on the above results, the null hypothesis can be rejected, but the statistic results in minimal to no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1bb40-fd11-479d-a2ee-b0338f470fa6",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "While the statistical test shows minimal corelation, we can still visually represent the results for the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f04b6-27a4-47a8-a580-b49706508343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
